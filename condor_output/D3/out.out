Activating Environment
Resetting Output/Results Files
Running Baseline: Naive Bayes Classifier
Running Finetuned Transformer LM Inference - TAMIL
Running Finetuned Transformer LM Inference - MALAYALAM
Running XLM Roberta last four layers RF + SMOTE - TAMIL
Text transformer: Pipeline(steps=[('xlm_roberta_base',
                 TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                            layers_to_combine=[-1, -2, -3, -4],
                                            model_max_length=512))])
Preprocessor: ColumnTransformer(n_jobs=-1,
                  transformers=[('text',
                                 Pipeline(steps=[('xlm_roberta_base',
                                                  TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                                                             layers_to_combine=[-1,
                                                                                                -2,
                                                                                                -3,
                                                                                                -4],
                                                                             model_max_length=512))]),
                                 'text')])
Resamplers: [('smote', SMOTE(k_neighbors=2, random_state=573))]
Classifier: ('classifier', RandomForestClassifier(n_jobs=-1, random_state=573))
Pipeline: Pipeline(memory='sklearn_cache/last4_xlm_roberta_rf.yml/classifier',
         steps=[('preprocessor',
                 ColumnTransformer(n_jobs=-1,
                                   transformers=[('text',
                                                  Pipeline(steps=[('xlm_roberta_base',
                                                                   TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                                                                              layers_to_combine=[-1,
                                                                                                                 -2,
                                                                                                                 -3,
                                                                                                                 -4],
                                                                                              model_max_length=512))]),
                                                  'text')])),
                ('smote', SMOTE(k_neighbors=2, random_state=573)),
                ('classifier',
                 RandomForestClassifier(n_jobs=-1, random_state=573))])
train_idxs: [ 6  8 13 15 17 18 19 20 21 22 23 24 25 27 28 29 30 31 32 33 34 35 36 37
 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53]
eval_idxs: [ 0  1  2  3  4  5  7  9 10 11 12 14 16 26]
y_true: [3, 3, 3, 4, 2, 3, 3, 3, 3, 3, 3, 2, 0, 1]
y_pred: [3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3]
train_idxs: [ 0  1  2  3  4  5  7  9 10 11 12 14 16 26 28 29 30 31 32 33 34 35 36 37
 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53]
eval_idxs: [ 6  8 13 15 17 18 19 20 21 22 23 24 25 27]
y_true: [4, 4, 3, 2, 3, 3, 3, 3, 3, 2, 3, 0, 3, 1]
y_pred: [3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3]
train_idxs: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 40 41 42 43 45 46 47 48 49 50 51 52 53]
eval_idxs: [28 29 30 31 32 33 34 35 36 37 38 39 44]
y_true: [3, 3, 3, 4, 3, 0, 3, 1, 3, 3, 3, 4, 2]
y_pred: [3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
train_idxs: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 44]
eval_idxs: [40 41 42 43 45 46 47 48 49 50 51 52 53]
y_true: [3, 3, 3, 3, 2, 1, 3, 0, 4, 3, 3, 4, 3]
y_pred: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         6
           3       0.60      0.91      0.72        33
           4       0.50      0.14      0.22         7

    accuracy                           0.57        54
   macro avg       0.22      0.21      0.19        54
weighted avg       0.43      0.57      0.47        54

Running XLM Roberta last four layers RF + SMOTE - MALAYALAM
Text transformer: Pipeline(steps=[('xlm_roberta_base',
                 TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                            layers_to_combine=[-1, -2, -3, -4],
                                            model_max_length=512))])
Preprocessor: ColumnTransformer(n_jobs=-1,
                  transformers=[('text',
                                 Pipeline(steps=[('xlm_roberta_base',
                                                  TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                                                             layers_to_combine=[-1,
                                                                                                -2,
                                                                                                -3,
                                                                                                -4],
                                                                             model_max_length=512))]),
                                 'text')])
Resamplers: [('smote', SMOTE(k_neighbors=2, random_state=573))]
Classifier: ('classifier', RandomForestClassifier(n_jobs=-1, random_state=573))
Pipeline: Pipeline(memory='sklearn_cache/last4_xlm_roberta_rf.yml/classifier',
         steps=[('preprocessor',
                 ColumnTransformer(n_jobs=-1,
                                   transformers=[('text',
                                                  Pipeline(steps=[('xlm_roberta_base',
                                                                   TransformerLayerVectorizer(language_model='xlm-roberta-base',
                                                                                              layers_to_combine=[-1,
                                                                                                                 -2,
                                                                                                                 -3,
                                                                                                                 -4],
                                                                                              model_max_length=512))]),
                                                  'text')])),
                ('smote', SMOTE(k_neighbors=2, random_state=573)),
                ('classifier',
                 RandomForestClassifier(n_jobs=-1, random_state=573))])
train_idxs: [10 13 16 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]
eval_idxs: [ 0  1  2  3  4  5  6  7  8  9 11 12 14 15 19]
DONE
