# @package _global_
defaults:
  - override /hydra/launcher: submitit_slurm
  - _self_
cleaned_override_dirname: ${lang}/${slash2under:${pipeline.text.vectorizer.language_model}}/${slash2under:${pipeline.audio_col}}/${clean_path:${hydra:job.override_dirname}}
# cleaned_override_dirname: ${lang}/${slash2under:${pipeline.text.vectorizer.language_model}}/${pipeline.text.vectorizer.layers_to_combine}/${clean_path:${hydra:job.override_dirname}}
results_file: outputs/${cleaned_override_dirname}/${seed}.pkl
lang: ???
dataset: ../data/${lang}/train_dataset_dict_featurized_audio
# dataset: ../data/${lang}/train_dataset_dict
hydra:
  callbacks:
    jobend_callback:
      _target_: pipeline_transformers.callbacks.MyLogJobReturnCallback
      # _target_: hydra.experimental.callbacks.LogJobReturnCallback
  launcher:
    account: stf
    cpus_per_task: 4
    # gpus_per_node: 1
    # gres: "gpu:rtx6k:1"
    gres: "gpu:a40:1"
    mem_gb: 48 # 36
    # partition: "gpu-2080ti"
    partition: ckpt
    timeout_min: 2880
    # additional_parameters:
    #   mail-user: "abhinavp@uw.edu"
    #   mail-type: "BEGIN,END,FAIL,ARRAY_TASKS"
    #   # mail-type: "ALL,ARRAY_TASKS"
  job:
    config:
      override_dirname:
        exclude_keys:
          - pipeline.audio_col
          - dataset
          - debug
          - experiment
          - launcher_config
          - lang
          - pipeline.text.vectorizer
          - pipeline.text.vectorizer.language_model
          # - pipeline.text.vectorizer.layers_to_combine
          - seed
          # - pipeline.classifier
        item_sep: ","
        kv_sep: "="
  sweep:
    # dir: multirun
    dir: multirun/${now:%m-%d-%H-%M}
    # dir: multirun/${hydra:job.override_dirname}
    subdir: ${cleaned_override_dirname}/${seed}
    # subdir: ${pipeline.classifier.__target__}/${hydra:job.override_dirname}/${seed}
  #   subdir: 
  # sweeper:
  #   params:
  #     classifiers@pipeline.classifier: rf, logistic
  #     +resamplers@pipeline.resamplers: smote, random_oversampler
  #     +transformers@pipeline.postresample_transformers: scaler, no_transformer
  #     # +transformers@pipeline.postresample_transformers: scaler, pca
  #     seed: 0, 42, 100, 573, 2023
  # verbose: ${debug}
  verbose: True
  # verbose: ["__main__", "
